#!/usr/bin/env python3
"""
Snowflake Replication Monitor
Monitors failover groups for replication failures and latency issues.
"""

import argparse
import logging
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import re
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

try:
    import snowflake.connector
    from croniter import croniter
except ImportError as e:
    print(f"Error: Missing required package. Please install: pip install snowflake-connector-python croniter")
    sys.exit(1)


def setup_logging(script_name: str) -> logging.Logger:
    """
    Set up logging configuration to write to a log file.

    Args:
        script_name: Name of the script (without .py extension)

    Returns:
        Configured logger instance
    """
    log_file = f"{script_name}.log"

    # Create logger
    logger = logging.getLogger(script_name)
    logger.setLevel(logging.INFO)

    # Create file handler
    file_handler = logging.FileHandler(log_file)
    file_handler.setLevel(logging.INFO)

    # Create console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    # Add handlers to logger
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


def connect_to_snowflake(
    account: str,
    user: str,
    password: Optional[str] = None,
    authenticator: Optional[str] = None,
    role: Optional[str] = None,
    warehouse: Optional[str] = None,
    logger: Optional[logging.Logger] = None
) -> snowflake.connector.SnowflakeConnection:
    """
    Connect to Snowflake account.

    Args:
        account: Snowflake account name
        user: Username for authentication
        password: Password (if using password auth)
        authenticator: Authentication method (e.g., 'externalbrowser')
        role: Role to use
        warehouse: Warehouse to use
        logger: Logger instance

    Returns:
        Snowflake connection object

    Raises:
        Exception: If connection fails
    """
    if logger:
        logger.info(f"Connecting to Snowflake account: {account}")

    try:
        conn_params = {
            'account': account,
            'user': user,
        }

        if password:
            conn_params['password'] = password

        if authenticator:
            conn_params['authenticator'] = authenticator

        if role:
            conn_params['role'] = role

        if warehouse:
            conn_params['warehouse'] = warehouse

        conn = snowflake.connector.connect(**conn_params)

        if logger:
            logger.info(f"Successfully connected to account: {account}")

        return conn

    except Exception as e:
        if logger:
            logger.error(f"Failed to connect to Snowflake account {account}: {str(e)}")
        raise


def get_failover_groups(conn: snowflake.connector.SnowflakeConnection, logger: logging.Logger) -> List[Dict]:
    """
    Execute 'SHOW FAILOVER GROUPS' and parse the results.

    Args:
        conn: Snowflake connection
        logger: Logger instance

    Returns:
        List of failover group information dictionaries
    """
    logger.info("Executing 'SHOW FAILOVER GROUPS' command")

    try:
        cursor = conn.cursor()
        cursor.execute("SHOW FAILOVER GROUPS")

        # Get column names
        columns = [col[0] for col in cursor.description]

        # Fetch all results
        results = cursor.fetchall()

        failover_groups = []
        for row in results:
            fg_dict = dict(zip(columns, row))
            failover_groups.append(fg_dict)
            logger.info(f"Found failover group: {fg_dict.get('name', 'UNKNOWN')}")

        cursor.close()
        logger.info(f"Retrieved {len(failover_groups)} failover group(s)")

        return failover_groups

    except Exception as e:
        logger.error(f"Error retrieving failover groups: {str(e)}")
        raise


def is_primary_account(failover_group: Dict) -> bool:
    """
    Determine if the current account is the primary for the failover group.

    Args:
        failover_group: Failover group information dictionary

    Returns:
        True if current account is primary, False otherwise
    """
    # Check the 'is_primary' or 'type' field
    is_primary = failover_group.get('is_primary', 'false').lower() == 'true'
    fg_type = failover_group.get('type', '').upper()

    return is_primary or fg_type == 'PRIMARY'


def get_secondary_account(failover_group: Dict, logger: logging.Logger) -> Optional[str]:
    """
    Extract the secondary account name from the failover group information.

    Args:
        failover_group: Failover group information dictionary
        logger: Logger instance

    Returns:
        Secondary account name or None if not found
    """
    try:
        # Try to get account locator from allowed_accounts or target_account
        allowed_accounts = failover_group.get('allowed_accounts', '')

        if allowed_accounts:
            # Parse allowed accounts - format may vary
            accounts = [acc.strip() for acc in allowed_accounts.split(',')]
            if accounts:
                logger.info(f"Found secondary account: {accounts[0]}")
                return accounts[0]

        # Alternative: check target_account field
        target_account = failover_group.get('target_account', '')
        if target_account:
            logger.info(f"Found target account: {target_account}")
            return target_account

        logger.warning("Could not determine secondary account from failover group")
        return None

    except Exception as e:
        logger.error(f"Error extracting secondary account: {str(e)}")
        return None


def parse_cron_schedule(schedule_str: Optional[str], logger: logging.Logger) -> Optional[int]:
    """
    Parse cron schedule and calculate interval in minutes.

    Args:
        schedule_str: Cron schedule string
        logger: Logger instance

    Returns:
        Interval in minutes, or None if parsing fails
    """
    if not schedule_str:
        logger.warning("No schedule string provided")
        return None

    try:
        # Create croniter instance
        base_time = datetime.now()
        cron = croniter(schedule_str, base_time)

        # Get next two execution times to calculate interval
        next_time = cron.get_next(datetime)
        following_time = cron.get_next(datetime)

        # Calculate interval in minutes
        interval = (following_time - next_time).total_seconds() / 60

        logger.info(f"Parsed cron schedule '{schedule_str}': interval = {interval} minutes")
        return int(interval)

    except Exception as e:
        logger.error(f"Error parsing cron schedule '{schedule_str}': {str(e)}")
        return None


def check_replication_status(
    conn: snowflake.connector.SnowflakeConnection,
    failover_group_name: str,
    logger: logging.Logger
) -> Dict:
    """
    Check the replication status for a specific failover group.

    Args:
        conn: Snowflake connection (to secondary account)
        failover_group_name: Name of the failover group
        logger: Logger instance

    Returns:
        Dictionary containing replication status information
    """
    logger.info(f"Checking replication status for failover group: {failover_group_name}")

    try:
        cursor = conn.cursor()

        # Query replication status
        query = f"""
        SELECT
            phase_name,
            start_time,
            end_time,
            progress,
            details
        FROM TABLE(INFORMATION_SCHEMA.REPLICATION_GROUP_REFRESH_PROGRESS('{failover_group_name}'))
        ORDER BY start_time DESC
        LIMIT 1
        """

        cursor.execute(query)
        result = cursor.fetchone()

        if result:
            columns = [col[0] for col in cursor.description]
            status = dict(zip(columns, result))
            logger.info(f"Latest replication phase: {status.get('PHASE_NAME', 'UNKNOWN')}")
        else:
            logger.warning(f"No replication history found for {failover_group_name}")
            status = {}

        cursor.close()
        return status

    except Exception as e:
        logger.error(f"Error checking replication status: {str(e)}")
        return {'error': str(e)}


def check_replication_failure(status: Dict, logger: logging.Logger) -> Tuple[bool, Optional[str]]:
    """
    Determine if the last replication failed.

    Args:
        status: Replication status dictionary
        logger: Logger instance

    Returns:
        Tuple of (is_failed: bool, error_message: Optional[str])
    """
    if 'error' in status:
        logger.error(f"Replication check error: {status['error']}")
        return True, status['error']

    phase_name = status.get('PHASE_NAME', '').upper()
    details = status.get('DETAILS', '')

    # Check for failure indicators
    failure_indicators = ['FAILED', 'ERROR', 'CANCELLED']

    for indicator in failure_indicators:
        if indicator in phase_name or indicator in details.upper():
            logger.warning(f"Replication failure detected: {phase_name} - {details}")
            return True, f"Phase: {phase_name}, Details: {details}"

    logger.info("No replication failure detected")
    return False, None


def check_replication_latency(
    status: Dict,
    cron_interval_minutes: int,
    logger: logging.Logger
) -> Tuple[bool, Optional[str]]:
    """
    Check if there is replication latency based on the cron schedule.

    Args:
        status: Replication status dictionary
        cron_interval_minutes: Expected replication interval in minutes
        logger: Logger instance

    Returns:
        Tuple of (has_latency: bool, message: Optional[str])
    """
    if not status or 'error' in status:
        logger.warning("Cannot check latency: no valid status data")
        return False, None

    try:
        end_time = status.get('END_TIME')
        start_time = status.get('START_TIME')

        if not end_time or not start_time:
            logger.warning("Missing start_time or end_time in replication status")
            return False, None

        # Calculate replication duration
        replication_duration = (end_time - start_time).total_seconds() / 60

        # Calculate time since last completion
        time_since_completion = (datetime.now() - end_time).total_seconds() / 60

        # Calculate latency threshold: interval + duration + 10% of duration
        latency_threshold = cron_interval_minutes + replication_duration + (0.1 * replication_duration)

        logger.info(f"Replication duration: {replication_duration:.2f} minutes")
        logger.info(f"Time since last completion: {time_since_completion:.2f} minutes")
        logger.info(f"Latency threshold: {latency_threshold:.2f} minutes")

        if time_since_completion > latency_threshold:
            message = (
                f"Latency detected! Time since completion ({time_since_completion:.2f} min) "
                f"exceeds threshold ({latency_threshold:.2f} min)"
            )
            logger.warning(message)
            return True, message

        logger.info("No latency detected")
        return False, None

    except Exception as e:
        logger.error(f"Error checking replication latency: {str(e)}")
        return False, None


def send_email_alert(
    subject: str,
    body: str,
    smtp_server: str,
    smtp_port: int,
    from_email: str,
    to_emails: List[str],
    smtp_user: Optional[str] = None,
    smtp_password: Optional[str] = None,
    logger: Optional[logging.Logger] = None
) -> bool:
    """
    Send email alert for replication issues.

    Args:
        subject: Email subject
        body: Email body
        smtp_server: SMTP server address
        smtp_port: SMTP port
        from_email: Sender email address
        to_emails: List of recipient email addresses
        smtp_user: SMTP username (if authentication required)
        smtp_password: SMTP password (if authentication required)
        logger: Logger instance

    Returns:
        True if email sent successfully, False otherwise
    """
    if logger:
        logger.info(f"Sending email alert: {subject}")

    try:
        # Create message
        msg = MIMEMultipart()
        msg['From'] = from_email
        msg['To'] = ', '.join(to_emails)
        msg['Subject'] = subject

        msg.attach(MIMEText(body, 'plain'))

        # Connect to SMTP server
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()

            if smtp_user and smtp_password:
                server.login(smtp_user, smtp_password)

            server.send_message(msg)

        if logger:
            logger.info(f"Email sent successfully to: {', '.join(to_emails)}")

        return True

    except Exception as e:
        if logger:
            logger.error(f"Failed to send email: {str(e)}")
        return False


def main():
    """Main function to monitor Snowflake replication."""

    # Parse command line arguments
    parser = argparse.ArgumentParser(
        description='Monitor Snowflake failover group replication'
    )
    parser.add_argument(
        '--account',
        required=True,
        help='Snowflake account name'
    )
    parser.add_argument(
        '--user',
        required=True,
        help='Snowflake username'
    )
    parser.add_argument(
        '--password',
        help='Snowflake password (or use --authenticator)'
    )
    parser.add_argument(
        '--authenticator',
        help='Authentication method (e.g., externalbrowser)'
    )
    parser.add_argument(
        '--role',
        help='Snowflake role to use'
    )
    parser.add_argument(
        '--warehouse',
        help='Snowflake warehouse to use'
    )
    parser.add_argument(
        '--smtp-server',
        help='SMTP server address for email alerts'
    )
    parser.add_argument(
        '--smtp-port',
        type=int,
        default=587,
        help='SMTP port (default: 587)'
    )
    parser.add_argument(
        '--from-email',
        help='Sender email address'
    )
    parser.add_argument(
        '--to-emails',
        help='Comma-separated list of recipient email addresses'
    )
    parser.add_argument(
        '--smtp-user',
        help='SMTP username for authentication'
    )
    parser.add_argument(
        '--smtp-password',
        help='SMTP password for authentication'
    )

    args = parser.parse_args()

    # Get script name without extension
    script_name = os.path.splitext(os.path.basename(__file__))[0]

    # Set up logging
    logger = setup_logging(script_name)

    logger.info("=" * 80)
    logger.info("Snowflake Replication Monitor Started")
    logger.info("=" * 80)

    try:
        # Step 1: Connect to Snowflake
        conn = connect_to_snowflake(
            account=args.account,
            user=args.user,
            password=args.password,
            authenticator=args.authenticator,
            role=args.role,
            warehouse=args.warehouse,
            logger=logger
        )

        # Step 2: Get failover groups
        failover_groups = get_failover_groups(conn, logger)

        if not failover_groups:
            logger.warning("No failover groups found")
            conn.close()
            return

        # Step 3: Process each failover group
        for fg in failover_groups:
            fg_name = fg.get('name', 'UNKNOWN')
            logger.info(f"\n{'=' * 60}")
            logger.info(f"Processing failover group: {fg_name}")
            logger.info(f"{'=' * 60}")

            # Get cron schedule
            schedule = fg.get('replication_schedule', '')
            next_scheduled = fg.get('next_scheduled_refresh', '')

            logger.info(f"Replication schedule: {schedule}")
            logger.info(f"Next scheduled refresh: {next_scheduled}")

            # Parse cron interval
            cron_interval = parse_cron_schedule(schedule, logger)

            if not cron_interval:
                logger.warning(f"Could not parse cron schedule for {fg_name}, skipping latency check")

            # Step 4: Check if we're on primary, if so connect to secondary
            check_conn = conn
            is_primary = is_primary_account(fg)

            logger.info(f"Current account is primary: {is_primary}")

            if is_primary:
                secondary_account = get_secondary_account(fg, logger)

                if secondary_account:
                    try:
                        logger.info(f"Connecting to secondary account: {secondary_account}")
                        check_conn = connect_to_snowflake(
                            account=secondary_account,
                            user=args.user,
                            password=args.password,
                            authenticator=args.authenticator,
                            role=args.role,
                            warehouse=args.warehouse,
                            logger=logger
                        )
                    except Exception as e:
                        logger.error(f"Failed to connect to secondary account: {str(e)}")
                        continue

            # Step 5: Check replication status
            status = check_replication_status(check_conn, fg_name, logger)

            # Step 6: Check for replication failure
            has_failure, failure_msg = check_replication_failure(status, logger)

            if has_failure:
                email_subject = f"ALERT: Snowflake Replication Failure - {fg_name}"
                email_body = f"""
Replication failure detected for failover group: {fg_name}

Account: {args.account}
Failure Message: {failure_msg}
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Please investigate immediately.
                """

                # Send email if configured
                if args.smtp_server and args.from_email and args.to_emails:
                    to_emails = [email.strip() for email in args.to_emails.split(',')]
                    send_email_alert(
                        subject=email_subject,
                        body=email_body,
                        smtp_server=args.smtp_server,
                        smtp_port=args.smtp_port,
                        from_email=args.from_email,
                        to_emails=to_emails,
                        smtp_user=args.smtp_user,
                        smtp_password=args.smtp_password,
                        logger=logger
                    )

            # Step 7: Check for replication latency
            if cron_interval:
                has_latency, latency_msg = check_replication_latency(
                    status,
                    cron_interval,
                    logger
                )

                if has_latency:
                    email_subject = f"ALERT: Snowflake Replication Latency - {fg_name}"
                    email_body = f"""
Replication latency detected for failover group: {fg_name}

Account: {args.account}
Latency Message: {latency_msg}
Expected Interval: {cron_interval} minutes
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Please investigate.
                    """

                    # Send email if configured
                    if args.smtp_server and args.from_email and args.to_emails:
                        to_emails = [email.strip() for email in args.to_emails.split(',')]
                        send_email_alert(
                            subject=email_subject,
                            body=email_body,
                            smtp_server=args.smtp_server,
                            smtp_port=args.smtp_port,
                            from_email=args.from_email,
                            to_emails=to_emails,
                            smtp_user=args.smtp_user,
                            smtp_password=args.smtp_password,
                            logger=logger
                        )

            # Close secondary connection if we opened one
            if check_conn != conn:
                check_conn.close()
                logger.info("Closed secondary account connection")

        # Close primary connection
        conn.close()
        logger.info("Closed primary account connection")

        logger.info("\n" + "=" * 80)
        logger.info("Snowflake Replication Monitor Completed Successfully")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"Fatal error in replication monitor: {str(e)}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
